import numpy as np
import pandas as pd 
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import layers
from time import perf_counter 
import os
from keras.callbacks import ModelCheckpoint
from keras.models import load_model
from tensorflow.keras.utils import plot_model


## Defining batch specfications
batch_size = 100
img_height = 250
img_width = 250



## loading training set
training_data = tf.keras.preprocessing.image_dataset_from_directory(
    'data/train',
    seed=42,
    image_size= (img_height, img_width),
    batch_size=batch_size,
    color_mode='rgb'
)




## loading validation dataset
validation_data =  tf.keras.preprocessing.image_dataset_from_directory(
    'data/val',
    seed=42,
    image_size= (img_height, img_width),
    batch_size=batch_size,
    color_mode='rgb'
)





## loading testing dataset
testing_data = tf.keras.preprocessing.image_dataset_from_directory(
    'data/test',
    seed=42,
    image_size= (img_height, img_width),
    batch_size=batch_size,
    color_mode='rgb'
)



testing_data


class_names = training_data.class_names
class_names


## Configuring dataset for performance
AUTOTUNE = tf.data.experimental.AUTOTUNE
training_data = training_data.cache().prefetch(buffer_size=AUTOTUNE)
testing_data = testing_data.cache().prefetch(buffer_size=AUTOTUNE)




## Defining Cnn
model = tf.keras.models.Sequential([
  layers.BatchNormalization(),
  layers.Conv2D(32, 3, activation='relu'), # Conv2D(f_size, filter_size, activation) # relu, sigmoid, softmax
  layers.MaxPooling2D(), # MaxPooling
  layers.Conv2D(64, 3, activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(128, 3, activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(256, 3, activation='relu'),
  layers.MaxPooling2D(),
  layers.Flatten(),
  layers.Dense(512, activation='relu'),
  layers.Dense(len(class_names), activation= 'softmax')
])

model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])





model.build((None, 250, 250, 3))
model.summary()




## lets train our CNN
checkpoint = ModelCheckpoint("model_weights.h5", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint]
history = model.fit(training_data, validation_data=validation_data, epochs = 20, callbacks=callbacks_list)





Epoch 1/20
2022-06-06 11:22:14.066808: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
8/8 [==============================] - 65s 7s/step - loss: 2.5193 - accuracy: 0.5209 - val_loss: 0.7599 - val_accuracy: 0.4694

Epoch 00001: val_accuracy improved from -inf to 0.46939, saving model to model_weights.h5
Epoch 2/20
8/8 [==============================] - 54s 7s/step - loss: 0.6576 - accuracy: 0.6220 - val_loss: 0.8252 - val_accuracy: 0.4694

Epoch 00002: val_accuracy did not improve from 0.46939
Epoch 3/20
8/8 [==============================] - 52s 7s/step - loss: 0.6425 - accuracy: 0.6030 - val_loss: 0.7865 - val_accuracy: 0.4898

Epoch 00003: val_accuracy improved from 0.46939 to 0.48980, saving model to model_weights.h5
Epoch 4/20
8/8 [==============================] - 54s 7s/step - loss: 0.6056 - accuracy: 0.6561 - val_loss: 0.6366 - val_accuracy: 0.5918

Epoch 00004: val_accuracy improved from 0.48980 to 0.59184, saving model to model_weights.h5
Epoch 5/20
8/8 [==============================] - 53s 7s/step - loss: 0.5768 - accuracy: 0.7029 - val_loss: 0.6719 - val_accuracy: 0.6531

Epoch 00005: val_accuracy improved from 0.59184 to 0.65306, saving model to model_weights.h5
Epoch 6/20
8/8 [==============================] - 54s 7s/step - loss: 0.5381 - accuracy: 0.7244 - val_loss: 0.6321 - val_accuracy: 0.7041

Epoch 00006: val_accuracy improved from 0.65306 to 0.70408, saving model to model_weights.h5
Epoch 7/20
8/8 [==============================] - 53s 7s/step - loss: 0.4682 - accuracy: 0.7649 - val_loss: 1.0061 - val_accuracy: 0.5816
...
Epoch 20/20
8/8 [==============================] - 53s 7s/step - loss: 0.0535 - accuracy: 0.9823 - val_loss: 0.4427 - val_accuracy: 0.8776

Epoch 00020: val_accuracy did not improve from 0.91837




###### serialize model structure to JSON
model_json = model.to_json()
with open("model.json", "w") as json_file:
    json_file.write(model_json)



## stats on training data
plt.plot(history.history['loss'], label = 'training loss')
plt.plot(history.history['accuracy'], label = 'training accuracy')
plt.grid(True)
plt.legend()




## stats on training data
plt.plot(history.history['val_loss'], label = 'validation loss')
plt.plot(history.history['val_accuracy'], label = 'validation accuracy')
plt.grid(True)
plt.legend()




## lets vizualize results on testing data
AccuracyVector = []
plt.figure(figsize=(30, 30))
for images, labels in testing_data.take(1):
    predictions = model.predict(images)
    predlabel = []
    prdlbl = []
    
    for mem in predictions:
        predlabel.append(class_names[np.argmax(mem)])
        prdlbl.append(np.argmax(mem))
    
    AccuracyVector = np.array(prdlbl) == labels
    for i in range(40):
        ax = plt.subplot(10, 4, i + 1)
        plt.imshow(images[i].numpy().astype("uint8"))
        plt.title('Pred: '+ predlabel[i]+' actl:'+class_names[labels[i]] )
        plt.axis('off')
        plt.grid(True)